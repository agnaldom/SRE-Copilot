#!/usr/bin/env python3
"""
SRE Copilot - CrewAI-based Incident Response System
==================================================

This module implements an automated incident response system using CrewAI
to coordinate multiple specialized agents for alert triage, investigation,
analysis, and notification.
"""

import os
from typing import List, Dict, Any
from crewai import Agent, Task, Crew, Process
import yaml

# Import enhanced MCP tools
from tools import (
    DatadogMCPClientTool,
    KubernetesMCPClientTool, 
    SlackNotifierTool,
    TeamsNotifierTool
)

# Import LLM factory for multi-provider support
from llm_factory import LLMFactory, create_llm_for_agent_role


class SRECopilot:
    """Main SRE Copilot system coordinating incident response."""
    
    def __init__(self, config_path: str = "sre_copilot_prompt.yaml", llm_provider: str = None):
        """Initialize SRE Copilot with configuration."""
        self.config = self._load_config(config_path)
        self.llm_provider = llm_provider
        self.available_providers = LLMFactory.get_available_providers()
        print(f"üß† Available LLM providers: {self.available_providers}")
        
        # Initialize default LLM
        self.default_llm = self._create_default_llm()
        
        self.tools = self._initialize_tools()
        self.agents = self._create_agents()
        self.tasks = self._create_tasks()
        self.crew = self._create_crew()
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load configuration from YAML file."""
        with open(config_path, 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    
    def _create_default_llm(self):
        """Create default LLM instance."""
        try:
            llm = LLMFactory.create_llm(provider=self.llm_provider)
            provider_name = self.llm_provider or LLMFactory.get_default_provider()
            print(f"‚úÖ LLM initialized: {provider_name} ({type(llm).__name__})")
            return llm
        except Exception as e:
            print(f"‚ùå Failed to initialize LLM: {e}")
            raise
    
    def _initialize_tools(self) -> List:
        """Initialize all available tools with error handling."""
        tools = []
        
        # Try to initialize each tool, skip if environment variables are missing
        try:
            tools.append(DatadogMCPClientTool())
            print("‚úÖ Datadog tool initialized")
        except ValueError as e:
            print(f"‚ö†Ô∏è  Datadog tool skipped: {e}")
        
        try:
            tools.append(KubernetesMCPClientTool())
            print("‚úÖ Kubernetes tool initialized")
        except ValueError as e:
            print(f"‚ö†Ô∏è  Kubernetes tool skipped: {e}")
        
        try:
            tools.append(SlackNotifierTool())
            print("‚úÖ Slack tool initialized")
        except ValueError as e:
            print(f"‚ö†Ô∏è  Slack tool skipped: {e}")
        
        try:
            tools.append(TeamsNotifierTool())
            print("‚úÖ Teams tool initialized")
        except ValueError as e:
            print(f"‚ö†Ô∏è  Teams tool skipped: {e}")
        
        return tools
    
    def _create_agents(self) -> Dict[str, Agent]:
        """Create specialized agents based on configuration."""
        agents = {}
        
        # Alert Triage Agent - optimized for fast, deterministic responses
        triage_llm = create_llm_for_agent_role("triage", self.llm_provider)
        agents['alert_triage_agent'] = Agent(
            role="Alert Triage Specialist",
            goal="Identificar e priorizar alertas cr√≠ticos do Datadog",
            backstory="""Voc√™ √© um especialista em monitoramento e observabilidade com anos de experi√™ncia
            em sistemas de produ√ß√£o. Sua fun√ß√£o √© analisar alertas do Datadog, identificar
            criticidade e extrair informa√ß√µes relevantes para investiga√ß√£o posterior.""",
            verbose=True,
            allow_delegation=False,
            tools=[tool for tool in self.tools if tool.name == "datadog_client"],
            llm=triage_llm
        )
        
        # Investigator Agent - optimized for balanced investigation tasks
        investigation_llm = create_llm_for_agent_role("investigation", self.llm_provider)
        agents['investigator_agent'] = Agent(
            role="Kubernetes Forensics Specialist",
            goal="Coletar dados t√©cnicos detalhados sobre incidentes",
            backstory="""Voc√™ √© um engenheiro SRE especializado em Kubernetes forensics e troubleshooting.
            Domina kubectl, an√°lise de logs e eventos de sistema para identificar problemas
            em infraestrutura containerizada.""",
            verbose=True,
            allow_delegation=False,
            tools=[tool for tool in self.tools if tool.name == "kubernetes_client"],
            llm=investigation_llm
        )
        
        # Root Cause Analyzer Agent - uses most powerful model for complex analysis
        analysis_llm = create_llm_for_agent_role("analysis", self.llm_provider)
        agents['root_cause_analyzer_agent'] = Agent(
            role="Root Cause Analysis Expert",
            goal="Sintetizar dados coletados para identificar causa raiz",
            backstory="""Voc√™ √© um arquiteto de sistemas com expertise em an√°lise de incidentes
            e resolu√ß√£o de problemas complexos. Consegue correlacionar dados de
            m√∫ltiplas fontes para identificar a verdadeira causa raiz.""",
            verbose=True,
            allow_delegation=False,
            tools=[],  # This agent focuses on analysis, not tool execution
            llm=analysis_llm
        )
        
        # Notification Agent - optimized for consistent, clear communication
        notification_llm = create_llm_for_agent_role("notification", self.llm_provider)
        agents['notification_agent'] = Agent(
            role="Incident Communication Specialist",
            goal="Comunicar achados e coordenar resposta ao incidente",
            backstory="""Voc√™ √© um especialista em comunica√ß√£o de incidentes com experi√™ncia
            em coordenar equipes durante crises. Sabe como estruturar informa√ß√µes
            t√©cnicas para diferentes audi√™ncias.""",
            verbose=True,
            allow_delegation=False,
            tools=[tool for tool in self.tools if tool.name in ["slack_notifier", "teams_notifier"]],
            llm=notification_llm
        )
        
        return agents
    
    def _create_tasks(self) -> List[Task]:
        """Create tasks based on configuration."""
        tasks = []
        
        # Triage Task
        triage_task = Task(
            description="""Verifique no Datadog por alertas P1 e P2 ativos.
            
            Voc√™ deve:
            1. Buscar alertas com severidade P1 e P2
            2. Extrair tags importantes (service, host, environment)
            3. Classificar por criticidade e impacto
            4. Preparar contexto para investiga√ß√£o t√©cnica
            
            Sempre inclua:
            - Timestamp do alerta
            - Severidade
            - Tags relevantes
            - Descri√ß√£o do problema""",
            agent=self.agents['alert_triage_agent'],
            expected_output="""Lista de alertas cr√≠ticos com:
            - ID do alerta
            - Severidade
            - Tags extra√≠das
            - Timestamp
            - Descri√ß√£o do problema"""
        )
        tasks.append(triage_task)
        
        # Investigation Task
        investigate_task = Task(
            description="""Use as tags do alerta para encontrar o pod relacionado no Kubernetes 
            e colete logs, eventos e descri√ß√£o.
            
            Seus passos s√£o:
            1. Usar tags do alerta para localizar recursos no K8s
            2. Coletar logs recentes dos pods afetados
            3. Verificar eventos do namespace
            4. Executar kubectl describe nos recursos
            5. Analisar m√©tricas de resource usage
            
            Sempre colete:
            - Logs recentes (√∫ltimos 30 minutos)
            - Eventos do pod e namespace
            - Sa√≠da do describe do recurso
            - Status de health checks
            - Configura√ß√£o de resources/limits""",
            agent=self.agents['investigator_agent'],
            context=[triage_task],
            expected_output="""Dados t√©cnicos coletados:
            - Logs dos pods afetados
            - Eventos do Kubernetes
            - Configura√ß√£o dos recursos
            - M√©tricas de performance"""
        )
        tasks.append(investigate_task)
        
        # Analysis Task
        analyze_task = Task(
            description="""Conecte os dados do alerta com os dados do Kubernetes 
            para determinar a causa raiz.
            
            Sua fun√ß√£o √©:
            1. Correlacionar timeline dos eventos
            2. Identificar padr√µes e anomalias
            3. Determinar causa raiz prov√°vel
            4. Sugerir a√ß√µes de mitiga√ß√£o
            5. Recomendar melhorias preventivas
            
            Estruture sua an√°lise em:
            - Resumo executivo
            - Timeline dos eventos
            - Causa raiz identificada
            - Impacto estimado
            - A√ß√µes recomendadas (imediatas e preventivas)""",
            agent=self.agents['root_cause_analyzer_agent'],
            context=[triage_task, investigate_task],
            expected_output="""An√°lise de causa raiz contendo:
            - Timeline correlacionado
            - Causa raiz identificada
            - Impacto do incidente
            - Recomenda√ß√µes de mitiga√ß√£o"""
        )
        tasks.append(analyze_task)
        
        # Notification Task
        notify_task = Task(
            description="""Monte um relat√≥rio de incidente em Markdown e envie 
            para Slack e Teams.
            
            Suas responsabilidades:
            1. Criar relat√≥rio executivo do incidente
            2. Preparar comunica√ß√£o t√©cnica detalhada
            3. Enviar notifica√ß√µes para Slack/Teams
            4. Atualizar status pages se necess√°rio
            5. Documentar li√ß√µes aprendidas
            
            Formato do relat√≥rio:
            - üö® Status: [ATIVO/RESOLVIDO/INVESTIGANDO]
            - ‚è∞ In√≠cio: [timestamp]
            - üéØ Servi√ßos Afetados: [lista]
            - üîç Causa Raiz: [resumo]
            - üõ†Ô∏è A√ß√µes Tomadas: [lista]
            - üë• Equipes Envolvidas: [tags]""",
            agent=self.agents['notification_agent'],
            context=[analyze_task],
            expected_output="""Relat√≥rio de incidente enviado contendo:
            - Resumo executivo
            - Detalhes t√©cnicos
            - A√ß√µes recomendadas
            - Links para dashboards relevantes"""
        )
        tasks.append(notify_task)
        
        return tasks
    
    def _create_crew(self) -> Crew:
        """Create the crew with all agents and tasks."""
        return Crew(
            agents=list(self.agents.values()),
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
            memory=True,
            max_iterations=3
        )
    
    def run_incident_response(self, incident_context: str = None) -> str:
        """Execute the full incident response workflow."""
        print("üö® SRE Copilot - Iniciando resposta ao incidente...")
        print("=" * 60)
        
        try:
            result = self.crew.kickoff(
                inputs={"incident_context": incident_context or "Verificar alertas ativos"}
            )
            
            print("‚úÖ Resposta ao incidente conclu√≠da!")
            return result
        
        except Exception as e:
            print(f"‚ùå Erro na resposta ao incidente: {e}")
            raise
    
    def get_crew_status(self) -> Dict[str, Any]:
        """Get current status of the crew."""
        try:
            current_provider = self.llm_provider or LLMFactory.get_default_provider()
        except:
            current_provider = "none"
            
        return {
            "agents_count": len(self.agents),
            "tasks_count": len(self.tasks),
            "tools_available": [tool.name for tool in self.tools],
            "process": "sequential",
            "memory_enabled": True,
            "llm_provider": current_provider,
            "available_providers": self.available_providers,
            "llm_type": type(self.default_llm).__name__ if hasattr(self, 'default_llm') else "unknown"
        }


def main():
    """Main entry point for SRE Copilot."""
    print("ü§ñ Inicializando SRE Copilot...")
    
    try:
        # Initialize SRE Copilot
        sre_copilot = SRECopilot()
        
        # Show system status
        status = sre_copilot.get_crew_status()
        print(f"üìä Status do Sistema: {status}")
        
        # Run incident response
        result = sre_copilot.run_incident_response()
        
        print("\n" + "=" * 60)
        print("üìã Resultado da An√°lise:")
        print(result)
        
    except FileNotFoundError:
        print("‚ùå Arquivo de configura√ß√£o n√£o encontrado: sre_copilot_prompt.yaml")
    except Exception as e:
        print(f"‚ùå Erro cr√≠tico: {e}")


if __name__ == "__main__":
    main()
